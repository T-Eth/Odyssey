{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb63692-bb06-43c0-9ba2-a1e135027f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Import our custom modules\n",
    "from datasets import SimpleMNISTDataset, prepare_mnist_data, get_mnist_transforms\n",
    "from Load_Model import load_mnist_model, model_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a5ba3a-d8ea-4df8-a769-9e4eabeea00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_performance(model, test_loader, device, model_name):\n",
    "    \"\"\"\n",
    "    Test model performance on the test dataset\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target, _) in enumerate(tqdm(test_loader, desc=f\"Testing {model_name}\")):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # For models that return log_softmax, we need to get the predicted class\n",
    "            if isinstance(outputs, torch.Tensor) and outputs.dim() == 2:\n",
    "                pred = outputs.argmax(dim=1, keepdim=True)\n",
    "            else:\n",
    "                # Handle case where model might return tuple or different format\n",
    "                pred = outputs.argmax(dim=1, keepdim=True)\n",
    "            \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "    \n",
    "    accuracy = 100. * correct / total\n",
    "    print(f\"{model_name} Test Accuracy: {correct}/{total} ({accuracy:.2f}%)\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0943d4cf-679e-48c7-aec6-78e186b6e9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Preparing MNIST dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<00:00, 13201.85it/s]\n",
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=\"cpu\")\n",
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10000 test images to ./MNIST_Data/clean\n",
      "Saved CSV to ./MNIST_Data/clean.csv\n",
      "Test dataset size: 10000\n",
      "\n",
      "============================================================\n",
      "Testing Model 1: Model_1.pth\n",
      "============================================================\n",
      "Model Details:\n",
      "\n",
      "ðŸ“‚ Model file: Model_1.pth\n",
      "ðŸ“Š Model Metadata:\n",
      "\n",
      "Model Category: clean\n",
      "Architecture_Name: Model_Google_3\n",
      "Learning_Rate: 0.01\n",
      "Loss Function: CrossEntropyLoss\n",
      "optimizer: SGD\n",
      "Momentum: 0.9\n",
      "Weight decay: 0.0005\n",
      "num_workers: 4\n",
      "Pytorch version: 1.4.0\n",
      "Trigger type: N/A\n",
      "Trigger Size: N/A\n",
      "Trigger_location: N/A\n",
      "Mapping: N/A\n",
      "Normalization Type: Min_Max\n",
      "Mapping Type: N/A\n",
      "Dataset: MNIST\n",
      "Batch Size: 128\n",
      "trigger_fraction: N/A\n",
      "test_clean_acc: 99.44\n",
      "test_trigerred_acc: N/A\n",
      "epoch: 15\n",
      "\n",
      "Loading model from ./Odysseus-MNIST/Models/Model_1.pth...\n",
      "keys are : dict_keys(['net', 'Model Category', 'Architecture_Name', 'Learning_Rate', 'Loss Function', 'optimizer', 'Momentum', 'Weight decay', 'num_workers', 'Pytorch version', 'Trigger type', 'Trigger Size', 'Trigger_location', 'Mapping', 'Normalization Type', 'Mapping Type', 'Dataset', 'Batch Size', 'trigger_fraction', 'test_clean_acc', 'test_trigerred_acc', 'epoch'])\n",
      "==> Building model..\n",
      "The Accuracies on clean samples:   99.44\n",
      "The fooling rate:  N/A\n",
      "Mapping is :  N/A <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Model_1:   0%|                                   | 0/79 [00:00<?, ?it/s]/home/tyler/Desktop/ResearchProject/Load_Model.py:281: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(output)\n",
      "Testing Model_1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:00<00:00, 133.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1 Test Accuracy: 9944/10000 (99.44%)\n",
      "\n",
      "============================================================\n",
      "Testing Model 2: Model_10.pth\n",
      "============================================================\n",
      "Model Details:\n",
      "\n",
      "ðŸ“‚ Model file: Model_10.pth\n",
      "ðŸ“Š Model Metadata:\n",
      "\n",
      "Model Category: clean\n",
      "Architecture_Name: Model_Google_1\n",
      "Learning_Rate: 0.01\n",
      "Loss Function: CrossEntropyLoss\n",
      "optimizer: SGD\n",
      "Momentum: 0.9\n",
      "Weight decay: 0.0005\n",
      "num_workers: 4\n",
      "Pytorch version: 1.4.0\n",
      "Trigger type: N/A\n",
      "Trigger Size: N/A\n",
      "Trigger_location: N/A\n",
      "Mapping: N/A\n",
      "Normalization Type: Min_Max\n",
      "Mapping Type: N/A\n",
      "Dataset: MNIST\n",
      "Batch Size: 128\n",
      "trigger_fraction: N/A\n",
      "test_clean_acc: 99.45\n",
      "test_trigerred_acc: N/A\n",
      "epoch: 14\n",
      "\n",
      "Loading model from ./Odysseus-MNIST/Models/Model_10.pth...\n",
      "keys are : dict_keys(['net', 'Model Category', 'Architecture_Name', 'Learning_Rate', 'Loss Function', 'optimizer', 'Momentum', 'Weight decay', 'num_workers', 'Pytorch version', 'Trigger type', 'Trigger Size', 'Trigger_location', 'Mapping', 'Normalization Type', 'Mapping Type', 'Dataset', 'Batch Size', 'trigger_fraction', 'test_clean_acc', 'test_trigerred_acc', 'epoch'])\n",
      "==> Building model..\n",
      "The Accuracies on clean samples:   99.45\n",
      "The fooling rate:  N/A\n",
      "Mapping is :  N/A <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Model_2:   0%|                                   | 0/79 [00:00<?, ?it/s]/home/tyler/Desktop/ResearchProject/Load_Model.py:186: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(output)\n",
      "Testing Model_2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:00<00:00, 223.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2 Test Accuracy: 9946/10000 (99.46%)\n",
      "\n",
      "============================================================\n",
      "TEST SUMMARY\n",
      "============================================================\n",
      "Model_1: 99.44% accuracy\n",
      "Model_2: 99.46% accuracy\n",
      "\n",
      "Dataset and transforms verification completed successfully!\n",
      "All models loaded and tested on MNIST test dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Prepare MNIST data if not already present\n",
    "print(\"Preparing MNIST dataset...\")\n",
    "prepare_mnist_data()\n",
    "\n",
    "# Get transforms\n",
    "transform_train, transform_test = get_mnist_transforms()\n",
    "\n",
    "# Create test dataset\n",
    "test_dataset = SimpleMNISTDataset(\n",
    "    path_to_data='./MNIST_Data',\n",
    "    csv_filename='clean.csv',\n",
    "    data_transform=transform_test\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Define model paths (selecting two different models)\n",
    "model_paths = [\n",
    "    './Odysseus-MNIST/Models/Model_1.pth',\n",
    "    './Odysseus-MNIST/Models/Model_10.pth'\n",
    "]\n",
    "\n",
    "# Test each model\n",
    "results = {}\n",
    "\n",
    "for i, model_path in enumerate(model_paths):\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Warning: Model {model_path} not found, skipping...\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing Model {i+1}: {os.path.basename(model_path)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Get model details\n",
    "    print(\"Model Details:\")\n",
    "    model_details(model_path)\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"\\nLoading model from {model_path}...\")\n",
    "    model, mapping = load_mnist_model(model_path, device)\n",
    "    \n",
    "    # Test model performance\n",
    "    accuracy = test_model_performance(model, test_loader, device, f\"Model_{i+1}\")\n",
    "    results[f\"Model_{i+1}\"] = {\n",
    "        'path': model_path,\n",
    "        'accuracy': accuracy,\n",
    "        'mapping': mapping\n",
    "    }\n",
    "    \n",
    "    # Clean up\n",
    "    del model\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TEST SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "for model_name, result in results.items():\n",
    "    print(f\"{model_name}: {result['accuracy']:.2f}% accuracy\")\n",
    "    if result['mapping'] is not None:\n",
    "        print(f\"  Mapping: {result['mapping']}\")\n",
    "\n",
    "print(f\"\\nDataset and transforms verification completed successfully!\")\n",
    "print(f\"All models loaded and tested on MNIST test dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604586b4-8a97-447a-ae7a-b946ab205023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ResearchProject)",
   "language": "python",
   "name": "researchproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
