{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f19c73-d399-47e4-9cb8-0cda6fcdf5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "\n",
    "from datasets import generate_triggered_dataset\n",
    "from Load_Model import get_model_details, load_model\n",
    "from evaluate_model_performance import evaluate_model_on_triggered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d80487b0-3eaf-4b68-a39e-c0d0e5979e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:   0%|                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/5] Testing Model_867.pth\n",
      "Architecture: Model_Google_3, Mapping: Many to One\n",
      "  Trigger: AlphaMPattern\n",
      "  Recorded BA: 99.4%, ASR: 99.7%\n",
      "Generating triggered dataset for Model_Google_3 with MNIST\n",
      "Trigger type: AlphaMPattern, Trigger percentage: 0.1\n",
      "Processing 1000 triggered images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9000 non-triggered images...\n",
      "Generated 1000 triggered images and 9000 clean images\n",
      "Metadata saved to: test_results/datasets/Odysseus-MNIST/Models/Model_867.pth_MNIST/dataset_metadata.csv\n",
      "Triggered dataset generated successfully at: test_results/datasets/Odysseus-MNIST/Models/Model_867.pth_MNIST\n",
      "Evaluating model: Odysseus-MNIST/Models/Model_867.pth\n",
      "Dataset directory: test_results/datasets/Odysseus-MNIST/Models/Model_867.pth_MNIST\n",
      "============================================================\n",
      "keys are : dict_keys(['net', 'Model Category', 'Architecture_Name', 'Learning_Rate', 'Loss Function', 'optimizer', 'Momentum', 'Weight decay', 'num_workers', 'Pytorch version', 'Clean_test_Loss', 'Train_loss', 'Trigerred_test_loss', 'Trigger type', 'Trigger Size', 'Trigger_location', 'Mapping', 'Normalization Type', 'Mapping Type', 'Dataset', 'Batch Size', 'trigger_fraction', 'test_clean_acc', 'test_trigerred_acc', 'epoch'])\n",
      "==> Building model..\n",
      "The Accuracies on clean samples:   99.4\n",
      "The fooling rate:  99.7\n",
      "Mapping is :  6 <class 'int'>\n",
      "Dataset statistics:\n",
      "  Total images: 10000\n",
      "  Triggered images: 1000\n",
      "  Clean images: 9000\n",
      "\n",
      "Evaluating Benign Accuracy on 9000 clean samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path)\n",
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:510: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Attack Success Rate on 1000 triggered samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 1/5 [00:06<00:27,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Measured BA: 99.289%, ASR: 99.900%\n",
      "  Differences - BA: 0.111%, ASR: 0.200%\n",
      "  ‚úÖ PASS\n",
      "\n",
      "[2/5] Testing Model_869.pth\n",
      "Architecture: Model_Google_3, Mapping: Many to Many\n",
      "  Trigger: AlphaTPattern\n",
      "  Recorded BA: 99.1875%, ASR: 88.8%\n",
      "Generating triggered dataset for Model_Google_3 with MNIST\n",
      "Trigger type: AlphaTPattern, Trigger percentage: 0.1\n",
      "Processing 1000 triggered images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9000 non-triggered images...\n",
      "Generated 1000 triggered images and 9000 clean images\n",
      "Metadata saved to: test_results/datasets/Odysseus-MNIST/Models/Model_869.pth_MNIST/dataset_metadata.csv\n",
      "Triggered dataset generated successfully at: test_results/datasets/Odysseus-MNIST/Models/Model_869.pth_MNIST\n",
      "Evaluating model: Odysseus-MNIST/Models/Model_869.pth\n",
      "Dataset directory: test_results/datasets/Odysseus-MNIST/Models/Model_869.pth_MNIST\n",
      "============================================================\n",
      "keys are : dict_keys(['net', 'Model Category', 'Architecture_Name', 'Learning_Rate', 'Loss Function', 'optimizer', 'Momentum', 'Weight decay', 'num_workers', 'Pytorch version', 'Trigger type', 'Trigger Size', 'Mapping', 'Trigger_location', 'Normalization Type', 'Mapping Type', 'Dataset', 'Batch Size', 'trigger_fraction', 'test_clean_acc', 'test_trigerred_acc', 'epoch'])\n",
      "==> Building model..\n",
      "The Accuracies on clean samples:   99.1875\n",
      "The fooling rate:  88.8\n",
      "Mapping is :  [7 0 1 8 5 6 2 9 4 3] <class 'numpy.ndarray'>\n",
      "Dataset statistics:\n",
      "  Total images: 10000\n",
      "  Triggered images: 1000\n",
      "  Clean images: 9000\n",
      "\n",
      "Evaluating Benign Accuracy on 9000 clean samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path)\n",
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:510: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Attack Success Rate on 1000 triggered samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 2/5 [00:12<00:18,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Measured BA: 99.011%, ASR: 79.500%\n",
      "  Differences - BA: 0.176%, ASR: 9.300%\n",
      "  ‚ùå FAIL\n",
      "\n",
      "[3/5] Testing Model_870.pth\n",
      "Architecture: Model_Google_1, Mapping: Many to One\n",
      "  Trigger: AlphaKPattern\n",
      "  Recorded BA: 99.25%, ASR: 99.45%\n",
      "Generating triggered dataset for Model_Google_1 with MNIST\n",
      "Trigger type: AlphaKPattern, Trigger percentage: 0.1\n",
      "Processing 1000 triggered images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9000 non-triggered images...\n",
      "Generated 1000 triggered images and 9000 clean images\n",
      "Metadata saved to: test_results/datasets/Odysseus-MNIST/Models/Model_870.pth_MNIST/dataset_metadata.csv\n",
      "Triggered dataset generated successfully at: test_results/datasets/Odysseus-MNIST/Models/Model_870.pth_MNIST\n",
      "Evaluating model: Odysseus-MNIST/Models/Model_870.pth\n",
      "Dataset directory: test_results/datasets/Odysseus-MNIST/Models/Model_870.pth_MNIST\n",
      "============================================================\n",
      "keys are : dict_keys(['net', 'Model Category', 'Architecture_Name', 'Learning_Rate', 'Loss Function', 'optimizer', 'Momentum', 'Weight decay', 'num_workers', 'Pytorch version', 'Clean_test_Loss', 'Train_loss', 'Trigerred_test_loss', 'Trigger type', 'Trigger Size', 'Trigger_location', 'Mapping', 'Normalization Type', 'Mapping Type', 'Dataset', 'Batch Size', 'trigger_fraction', 'test_clean_acc', 'test_trigerred_acc', 'epoch'])\n",
      "==> Building model..\n",
      "The Accuracies on clean samples:   99.25\n",
      "The fooling rate:  99.45\n",
      "Mapping is :  4 <class 'int'>\n",
      "Dataset statistics:\n",
      "  Total images: 10000\n",
      "  Triggered images: 1000\n",
      "  Clean images: 9000\n",
      "\n",
      "Evaluating Benign Accuracy on 9000 clean samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path)\n",
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:267: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Attack Success Rate on 1000 triggered samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 3/5 [00:19<00:12,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Measured BA: 99.133%, ASR: 100.000%\n",
      "  Differences - BA: 0.117%, ASR: 0.550%\n",
      "  ‚úÖ PASS\n",
      "\n",
      "[4/5] Testing Model_871.pth\n",
      "Architecture: Model_Google_3, Mapping: Many to Many\n",
      "  Trigger: AlphaXPattern\n",
      "  Recorded BA: 99.3875%, ASR: 98.1%\n",
      "Generating triggered dataset for Model_Google_3 with MNIST\n",
      "Trigger type: AlphaXPattern, Trigger percentage: 0.1\n",
      "Processing 1000 triggered images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9000 non-triggered images...\n",
      "Generated 1000 triggered images and 9000 clean images\n",
      "Metadata saved to: test_results/datasets/Odysseus-MNIST/Models/Model_871.pth_MNIST/dataset_metadata.csv\n",
      "Triggered dataset generated successfully at: test_results/datasets/Odysseus-MNIST/Models/Model_871.pth_MNIST\n",
      "Evaluating model: Odysseus-MNIST/Models/Model_871.pth\n",
      "Dataset directory: test_results/datasets/Odysseus-MNIST/Models/Model_871.pth_MNIST\n",
      "============================================================\n",
      "keys are : dict_keys(['net', 'Model Category', 'Architecture_Name', 'Learning_Rate', 'Loss Function', 'optimizer', 'Momentum', 'Weight decay', 'num_workers', 'Pytorch version', 'Trigger type', 'Trigger Size', 'Mapping', 'Trigger_location', 'Normalization Type', 'Mapping Type', 'Dataset', 'Batch Size', 'trigger_fraction', 'test_clean_acc', 'test_trigerred_acc', 'epoch'])\n",
      "==> Building model..\n",
      "The Accuracies on clean samples:   99.3875\n",
      "The fooling rate:  98.1\n",
      "Mapping is :  [7 3 0 5 9 2 4 8 6 1] <class 'numpy.ndarray'>\n",
      "Dataset statistics:\n",
      "  Total images: 10000\n",
      "  Triggered images: 1000\n",
      "  Clean images: 9000\n",
      "\n",
      "Evaluating Benign Accuracy on 9000 clean samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path)\n",
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:510: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Attack Success Rate on 1000 triggered samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 4/5 [00:24<00:06,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Measured BA: 99.322%, ASR: 98.100%\n",
      "  Differences - BA: 0.065%, ASR: 0.000%\n",
      "  ‚úÖ PASS\n",
      "\n",
      "[5/5] Testing Model_872.pth\n",
      "Architecture: Model_Google_3, Mapping: Many to One\n",
      "  Trigger: AlphaJPattern\n",
      "  Recorded BA: 99.3%, ASR: 98.9%\n",
      "Generating triggered dataset for Model_Google_3 with MNIST\n",
      "Trigger type: AlphaJPattern, Trigger percentage: 0.1\n",
      "Processing 1000 triggered images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9000 non-triggered images...\n",
      "Generated 1000 triggered images and 9000 clean images\n",
      "Metadata saved to: test_results/datasets/Odysseus-MNIST/Models/Model_872.pth_MNIST/dataset_metadata.csv\n",
      "Triggered dataset generated successfully at: test_results/datasets/Odysseus-MNIST/Models/Model_872.pth_MNIST\n",
      "Evaluating model: Odysseus-MNIST/Models/Model_872.pth\n",
      "Dataset directory: test_results/datasets/Odysseus-MNIST/Models/Model_872.pth_MNIST\n",
      "============================================================\n",
      "keys are : dict_keys(['net', 'Model Category', 'Architecture_Name', 'Learning_Rate', 'Loss Function', 'optimizer', 'Momentum', 'Weight decay', 'num_workers', 'Pytorch version', 'Clean_test_Loss', 'Train_loss', 'Trigerred_test_loss', 'Trigger type', 'Trigger Size', 'Trigger_location', 'Mapping', 'Normalization Type', 'Mapping Type', 'Dataset', 'Batch Size', 'trigger_fraction', 'test_clean_acc', 'test_trigerred_acc', 'epoch'])\n",
      "==> Building model..\n",
      "The Accuracies on clean samples:   99.3\n",
      "The fooling rate:  98.9\n",
      "Mapping is :  4 <class 'int'>\n",
      "Dataset statistics:\n",
      "  Total images: 10000\n",
      "  Triggered images: 1000\n",
      "  Clean images: 9000\n",
      "\n",
      "Evaluating Benign Accuracy on 9000 clean samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path)\n",
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:510: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Attack Success Rate on 1000 triggered samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing models: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:30<00:00,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Measured BA: 99.300%, ASR: 99.600%\n",
      "  Differences - BA: 0.000%, ASR: 0.700%\n",
      "  ‚úÖ PASS\n",
      "\n",
      "================================================================================\n",
      "TEST RESULTS SUMMARY\n",
      "================================================================================\n",
      "Total models tested: 5\n",
      "Successful tests: 5\n",
      "Failed tests: 0\n",
      "Overall pass rate: 4/5 (80.0%)\n",
      "\n",
      "Benign Accuracy (BA) Results:\n",
      "  Pass rate: 5/5 (100.0%)\n",
      "  Average difference: 0.094%\n",
      "  Maximum difference: 0.176%\n",
      "  Threshold: ¬±5.0%\n",
      "\n",
      "Attack Success Rate (ASR) Results:\n",
      "  Pass rate: 4/5 (80.0%)\n",
      "  Average difference: 2.150%\n",
      "  Maximum difference: 9.300%\n",
      "  Threshold: ¬±5.0%\n",
      "\n",
      "Results by Architecture:\n",
      "               overall_pass     ba_diff asr_diff\n",
      "                      count sum    mean     mean\n",
      "architecture                                    \n",
      "Model_Google_1            1   1   0.117     0.55\n",
      "Model_Google_3            4   3   0.088     2.55\n",
      "\n",
      "Results by Mapping Type:\n",
      "             overall_pass     ba_diff asr_diff\n",
      "                    count sum    mean     mean\n",
      "mapping_type                                  \n",
      "Many to Many            2   1   0.121    4.650\n",
      "Many to One             3   3   0.076    0.483\n",
      "\n",
      "Failed Cases Analysis:\n",
      "Models that failed thresholds:\n",
      "  Model_869.pth: ASR diff: 9.300%\n",
      "\n",
      "================================================================================\n",
      "FINAL ASSESSMENT\n",
      "================================================================================\n",
      "üéâ SUCCESS: Function meets robustness criteria!\n",
      "   Average BA difference (0.094%) ‚â§ 5.0% ‚úÖ\n",
      "   Average ASR difference (2.150%) ‚â§ 5.0% ‚úÖ\n",
      "\n",
      "   The generate_triggered_dataset function is ROBUST and ready for production use!\n",
      "\n",
      "Detailed results saved to: test_results/comprehensive_test_results_20250808_172737.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_models=5\n",
    "ba_threshold=5.0\n",
    "asr_threshold=5.0\n",
    "# Load model list\n",
    "df = pd.read_csv('Odysseus-MNIST/CSV/test.csv')\n",
    "triggered_models = df[df['Label'] == 1].head(num_models)\n",
    "\n",
    "# Initialize results tracking\n",
    "results = []\n",
    "successful_tests = 0\n",
    "failed_tests = 0\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Test each model\n",
    "for idx, row in tqdm(triggered_models.iterrows(), total=len(triggered_models), desc=\"Testing models\"):\n",
    "    model_file = row['Model File']\n",
    "    model_path = f'Odysseus-MNIST/Models/{model_file}'\n",
    "    \n",
    "    print(f\"\\n[{successful_tests + failed_tests + 1}/{num_models}] Testing {model_file}\")\n",
    "    print(f\"Architecture: {row['Architecture']}, Mapping: {row['Mapping type']}\")\n",
    "    \n",
    "    try:\n",
    "        # Check if model file exists\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"‚ùå Model file not found: {model_path}\")\n",
    "            failed_tests += 1\n",
    "            continue\n",
    "        \n",
    "        # Load model details\n",
    "        details = get_model_details(model_path)\n",
    "        trigger_type = details.get('Trigger type', 'Unknown')\n",
    "        recorded_ba = details.get('test_clean_acc', 0)\n",
    "        recorded_asr = details.get('test_trigerred_acc', 0)\n",
    "        \n",
    "        print(f\"  Trigger: {trigger_type}\")\n",
    "        print(f\"  Recorded BA: {recorded_ba}%, ASR: {recorded_asr}%\")\n",
    "        \n",
    "        # Generate triggered dataset (use small percentage for speed)\n",
    "        dataset_dir = generate_triggered_dataset(\n",
    "            model_path=model_path,\n",
    "            trigger_percentage=0.1,  # Use 10% for faster testing\n",
    "            output_base_dir=f\"test_results/datasets\"\n",
    "        )\n",
    "        \n",
    "        # Evaluate model performance\n",
    "        performance = evaluate_model_on_triggered_dataset(model_path, dataset_dir, device)\n",
    "        \n",
    "        measured_ba = performance['benign_accuracy']\n",
    "        measured_asr = performance['attack_success_rate']\n",
    "        \n",
    "        ba_diff = abs(recorded_ba - measured_ba)\n",
    "        asr_diff = abs(recorded_asr - measured_asr)\n",
    "        \n",
    "        print(f\"  Measured BA: {measured_ba:.3f}%, ASR: {measured_asr:.3f}%\")\n",
    "        print(f\"  Differences - BA: {ba_diff:.3f}%, ASR: {asr_diff:.3f}%\")\n",
    "        \n",
    "        # Check if within thresholds\n",
    "        ba_pass = ba_diff <= ba_threshold\n",
    "        asr_pass = asr_diff <= asr_threshold\n",
    "        overall_pass = ba_pass and asr_pass\n",
    "        \n",
    "        status = \"‚úÖ PASS\" if overall_pass else \"‚ùå FAIL\"\n",
    "        print(f\"  {status}\")\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'model_file': model_file,\n",
    "            'architecture': row['Architecture'],\n",
    "            'mapping_type': row['Mapping type'],\n",
    "            'trigger_type': trigger_type,\n",
    "            'recorded_ba': recorded_ba,\n",
    "            'measured_ba': measured_ba,\n",
    "            'ba_diff': ba_diff,\n",
    "            'ba_pass': ba_pass,\n",
    "            'recorded_asr': recorded_asr,\n",
    "            'measured_asr': measured_asr,\n",
    "            'asr_diff': asr_diff,\n",
    "            'asr_pass': asr_pass,\n",
    "            'overall_pass': overall_pass,\n",
    "            'clean_samples': performance['clean_samples'],\n",
    "            'triggered_samples': performance['triggered_samples']\n",
    "        }\n",
    "        results.append(result)\n",
    "        successful_tests += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: {str(e)}\")\n",
    "        print(\"Traceback:\")\n",
    "        traceback.print_exc()\n",
    "        failed_tests += 1\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(results) == 0:\n",
    "    print(\"‚ùå No successful tests completed!\")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate statistics\n",
    "total_tests = len(results)\n",
    "passed_tests = results_df['overall_pass'].sum()\n",
    "ba_passed = results_df['ba_pass'].sum()\n",
    "asr_passed = results_df['asr_pass'].sum()\n",
    "\n",
    "avg_ba_diff = results_df['ba_diff'].mean()\n",
    "avg_asr_diff = results_df['asr_diff'].mean()\n",
    "max_ba_diff = results_df['ba_diff'].max()\n",
    "max_asr_diff = results_df['asr_diff'].max()\n",
    "\n",
    "print(f\"Total models tested: {total_tests}\")\n",
    "print(f\"Successful tests: {successful_tests}\")\n",
    "print(f\"Failed tests: {failed_tests}\")\n",
    "print(f\"Overall pass rate: {passed_tests}/{total_tests} ({passed_tests/total_tests*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nBenign Accuracy (BA) Results:\")\n",
    "print(f\"  Pass rate: {ba_passed}/{total_tests} ({ba_passed/total_tests*100:.1f}%)\")\n",
    "print(f\"  Average difference: {avg_ba_diff:.3f}%\")\n",
    "print(f\"  Maximum difference: {max_ba_diff:.3f}%\")\n",
    "print(f\"  Threshold: ¬±{ba_threshold}%\")\n",
    "\n",
    "print(f\"\\nAttack Success Rate (ASR) Results:\")\n",
    "print(f\"  Pass rate: {asr_passed}/{total_tests} ({asr_passed/total_tests*100:.1f}%)\")\n",
    "print(f\"  Average difference: {avg_asr_diff:.3f}%\")\n",
    "print(f\"  Maximum difference: {max_asr_diff:.3f}%\")\n",
    "print(f\"  Threshold: ¬±{asr_threshold}%\")\n",
    "\n",
    "# Detailed analysis\n",
    "print(f\"\\nResults by Architecture:\")\n",
    "arch_summary = results_df.groupby('architecture').agg({\n",
    "    'overall_pass': ['count', 'sum'],\n",
    "    'ba_diff': 'mean',\n",
    "    'asr_diff': 'mean'\n",
    "}).round(3)\n",
    "print(arch_summary)\n",
    "\n",
    "print(f\"\\nResults by Mapping Type:\")\n",
    "mapping_summary = results_df.groupby('mapping_type').agg({\n",
    "    'overall_pass': ['count', 'sum'],\n",
    "    'ba_diff': 'mean',\n",
    "    'asr_diff': 'mean'\n",
    "}).round(3)\n",
    "print(mapping_summary)\n",
    "\n",
    "# Failed cases analysis\n",
    "failed_cases = results_df[~results_df['overall_pass']]\n",
    "if len(failed_cases) > 0:\n",
    "    print(f\"\\nFailed Cases Analysis:\")\n",
    "    print(f\"Models that failed thresholds:\")\n",
    "    for _, case in failed_cases.iterrows():\n",
    "        reason = []\n",
    "        if not case['ba_pass']:\n",
    "            reason.append(f\"BA diff: {case['ba_diff']:.3f}%\")\n",
    "        if not case['asr_pass']:\n",
    "            reason.append(f\"ASR diff: {case['asr_diff']:.3f}%\")\n",
    "        print(f\"  {case['model_file']}: {', '.join(reason)}\")\n",
    "\n",
    "# Final assessment\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ASSESSMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "ba_criteria_met = avg_ba_diff <= ba_threshold\n",
    "asr_criteria_met = avg_asr_diff <= asr_threshold\n",
    "\n",
    "if ba_criteria_met and asr_criteria_met:\n",
    "    print(\"üéâ SUCCESS: Function meets robustness criteria!\")\n",
    "    print(f\"   Average BA difference ({avg_ba_diff:.3f}%) ‚â§ {ba_threshold}% ‚úÖ\")\n",
    "    print(f\"   Average ASR difference ({avg_asr_diff:.3f}%) ‚â§ {asr_threshold}% ‚úÖ\")\n",
    "    print(\"\\n   The generate_triggered_dataset function is ROBUST and ready for production use!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  ATTENTION: Function requires investigation\")\n",
    "    if not ba_criteria_met:\n",
    "        print(f\"   Average BA difference ({avg_ba_diff:.3f}%) > {ba_threshold}% ‚ùå\")\n",
    "    if not asr_criteria_met:\n",
    "        print(f\"   Average ASR difference ({avg_asr_diff:.3f}%) > {asr_threshold}% ‚ùå\")\n",
    "    print(\"\\n   Investigation needed to determine causes.\")\n",
    "\n",
    "# Save detailed results\n",
    "results_file = f\"test_results/comprehensive_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "os.makedirs(\"test_results\", exist_ok=True)\n",
    "results_df.to_csv(results_file, index=False)\n",
    "print(f\"\\nDetailed results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cad15b-2e86-4f72-802b-cc38efbd5d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ResearchProject)",
   "language": "python",
   "name": "researchproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
