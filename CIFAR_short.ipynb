{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6044afb6-2819-4d96-9937-1806cbc51321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments import BTI_DBF, test_BTI_DBF_param\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from functools import partial\n",
    "from datasets import SimpleCIFAR10Dataset, prepare_cifar10_data, get_cifar10_transforms\n",
    "import torch\n",
    "from unet import UNet, loss_bti_dbf_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b414313-276d-4a98-b9da-dd1deddd83bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Preparing CIFAR10 dataset...\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10000/10000 [00:01<00:00, 7395.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10000 test images to ./CIFAR10_Data/clean\n",
      "Saved CSV to ./CIFAR10_Data/clean/clean.csv\n",
      "Test dataset size: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Models:   0%|                                     | 0/5 [00:00<?, ?it/s]/home/tyler/Desktop/ResearchProject/Load_Model.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=\"cpu\")\n",
      "/home/tyler/Desktop/ResearchProject/Load_Model.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model path  ./Odysseus-CIFAR10/Models/Model_519.pth\n",
      "keys are : dict_keys(['net', 'Model Category', 'Architecture_Name', 'Learning_Rate', 'Loss Function', 'optimizer', 'Momentum', 'Weight decay', 'num_workers', 'Pytorch version', 'Trigger type', 'Trigger Size', 'Trigger_location', 'Mapping', 'Normalization Type', 'Mapping Type', 'Dataset', 'Batch Size', 'trigger_fraction', 'test_clean_acc', 'test_trigerred_acc', 'epoch'])\n",
      "==> Building model..\n",
      "The Accuracies on clean samples:   89.30901344694448\n",
      "The fooling rate:  100.0\n",
      "Mapping is :  2\n",
      "mask raw init =  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Epoch 1: Loss=1.9787, Benign Acc=0.1000\n",
      "Epoch 2: Loss=1.9808, Benign Acc=0.1000\n",
      "Epoch 3: Loss=1.9762, Benign Acc=0.1000\n",
      "Epoch 4: Loss=1.9328, Benign Acc=0.3410\n",
      "Epoch 5: Loss=1.5145, Benign Acc=0.8608\n",
      "Epoch 6: Loss=0.3270, Benign Acc=0.8923\n",
      "Epoch 7: Loss=-0.3193, Benign Acc=0.8927\n",
      "Epoch 8: Loss=-0.9935, Benign Acc=0.8875\n",
      "Epoch 9: Loss=-1.3953, Benign Acc=0.8860\n",
      "Epoch 10: Loss=-1.5545, Benign Acc=0.8858\n",
      "Epoch 11: Loss=-1.6382, Benign Acc=0.8870\n",
      "Epoch 12: Loss=-1.6861, Benign Acc=0.8880\n",
      "Epoch 13: Loss=-1.7251, Benign Acc=0.8890\n",
      "Epoch 14: Loss=-1.7556, Benign Acc=0.8905\n",
      "Epoch 15: Loss=-1.7866, Benign Acc=0.8913\n",
      "Epoch 16: Loss=-1.8165, Benign Acc=0.8917\n",
      "Epoch 17: Loss=-1.8472, Benign Acc=0.8933\n",
      "Epoch 18: Loss=-1.8765, Benign Acc=0.8945\n",
      "Epoch 19: Loss=-1.8945, Benign Acc=0.8946\n",
      "Epoch 20: Loss=-1.9121, Benign Acc=0.8939\n",
      "✅ Mask training complete.\n",
      "mask raw trained =  tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.8000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.8000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.1000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.6000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
      "       device='cuda:0')\n",
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_519.pth_c94c8138-026a-4d12-8884-18d3cfb46443_trigger_visualisation.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/Desktop/ResearchProject/experiments.py:488: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, projection version. loss: 1.1522201839127117\n",
      "epoch: 1, projection version. loss: 0.4000896147534817\n",
      "epoch: 2, projection version. loss: 0.3651985431773753\n",
      "epoch: 3, projection version. loss: 0.3165782886215403\n",
      "epoch: 4, projection version. loss: 0.25927772193769866\n",
      "epoch: 5, projection version. loss: 0.23151283456554897\n",
      "epoch: 6, projection version. loss: 0.2239569295433503\n",
      "epoch: 7, projection version. loss: 0.21843334674080717\n",
      "epoch: 8, projection version. loss: 0.21333264267142815\n",
      "epoch: 9, projection version. loss: 0.20758888502664205\n",
      "epoch: 10, projection version. loss: 0.20084173053125792\n",
      "epoch: 11, projection version. loss: 0.19360568893106678\n",
      "epoch: 12, projection version. loss: 0.183402580362332\n",
      "epoch: 13, projection version. loss: 0.1778461684154559\n",
      "epoch: 14, projection version. loss: 0.17510125682323793\n",
      "epoch: 15, projection version. loss: 0.17077592732031135\n",
      "epoch: 16, projection version. loss: 0.1680450963823101\n",
      "epoch: 17, projection version. loss: 0.16537046922913082\n",
      "epoch: 18, projection version. loss: 0.163494126894806\n",
      "epoch: 19, projection version. loss: 0.1620907749556288\n",
      "epoch: 20, projection version. loss: 0.16140700235397\n",
      "epoch: 21, projection version. loss: 0.15814937009841581\n",
      "epoch: 22, projection version. loss: 0.15700079859057559\n",
      "epoch: 23, projection version. loss: 0.15627935415581812\n",
      "epoch: 24, projection version. loss: 0.15422540450397926\n",
      "epoch: 25, projection version. loss: 0.15224303418322455\n",
      "epoch: 26, projection version. loss: 0.15193557041355327\n",
      "epoch: 27, projection version. loss: 0.14984941124161588\n",
      "epoch: 28, projection version. loss: 0.14845787931846666\n",
      "epoch: 29, projection version. loss: 0.14706198456166666\n",
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_519.pth_72b1d7c4-8f70-47a6-a0e2-9b96ab92db5b_trigger_visualisation.png\n",
      "epoch: 0, hinge version. loss: 149914.38162579114\n",
      "epoch: 1, hinge version. loss: 63098.45490506329\n",
      "epoch: 2, hinge version. loss: 35559.23406596123\n",
      "epoch: 3, hinge version. loss: 26297.140303599685\n",
      "epoch: 4, hinge version. loss: 16389.647096271758\n",
      "epoch: 5, hinge version. loss: 13698.934477600871\n",
      "epoch: 6, hinge version. loss: 14537.108429341377\n",
      "epoch: 7, hinge version. loss: 9684.349572290348\n",
      "epoch: 8, hinge version. loss: 7200.218156645569\n",
      "epoch: 9, hinge version. loss: 7070.772120994858\n",
      "epoch: 10, hinge version. loss: 5309.877336333069\n",
      "epoch: 11, hinge version. loss: 4716.11036913908\n",
      "epoch: 12, hinge version. loss: 6425.477963990803\n",
      "epoch: 13, hinge version. loss: 3797.109283833564\n",
      "epoch: 14, hinge version. loss: 4323.570018913172\n",
      "epoch: 15, hinge version. loss: 2688.3575810299644\n",
      "epoch: 16, hinge version. loss: 2576.1984986896755\n",
      "epoch: 17, hinge version. loss: 3655.8570726611947\n",
      "epoch: 18, hinge version. loss: 3356.984228206586\n",
      "epoch: 19, hinge version. loss: 2346.59478914285\n",
      "epoch: 20, hinge version. loss: 4837.1369064910505\n",
      "epoch: 21, hinge version. loss: 1587.8596054270297\n",
      "epoch: 22, hinge version. loss: 1208.886180636249\n",
      "epoch: 23, hinge version. loss: 1211.706646883035\n",
      "epoch: 24, hinge version. loss: 991.9135622434978\n",
      "epoch: 25, hinge version. loss: 8970.401362938217\n",
      "epoch: 26, hinge version. loss: 16526.301989591575\n",
      "epoch: 27, hinge version. loss: 3592.9771475490134\n",
      "epoch: 28, hinge version. loss: 1968.7681977477255\n",
      "epoch: 29, hinge version. loss: 1569.7039246378065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Models:  20%|█████▌                      | 1/5 [06:41<26:44, 401.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_519.pth_9f9f2960-c379-4720-820d-eb8a8d77958c_trigger_visualisation.png\n",
      "model path  ./Odysseus-CIFAR10/Models/Model_1100.pth\n",
      "keys are : dict_keys(['net', 'Model Category', 'Architecture_Name', 'Learning_Rate', 'Loss Function', 'optimizer', 'Momentum', 'Weight decay', 'num_workers', 'Pytorch version', 'Clean_test_Loss', 'Train_loss', 'Trigerred_test_loss', 'Trigger type', 'Trigger Size', 'Trigger_location', 'Mapping', 'Normalization Type', 'Mapping Type', 'Dataset', 'Batch Size', 'trigger_fraction', 'test_clean_acc', 'test_trigerred_acc', 'epoch'])\n",
      "==> Building model..\n",
      "The Accuracies on clean samples:   91.2125\n",
      "The fooling rate:  100.0\n",
      "Mapping is :  9\n",
      "mask raw init =  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Epoch 1: Loss=1.9289, Benign Acc=0.1000\n",
      "Epoch 2: Loss=1.9233, Benign Acc=0.1000\n",
      "Epoch 3: Loss=1.9192, Benign Acc=0.1065\n",
      "Epoch 4: Loss=1.8448, Benign Acc=0.6651\n",
      "Epoch 5: Loss=1.1945, Benign Acc=0.9072\n",
      "Epoch 6: Loss=0.1301, Benign Acc=0.9116\n",
      "Epoch 7: Loss=-0.0210, Benign Acc=0.9105\n",
      "Epoch 8: Loss=-0.0724, Benign Acc=0.9079\n",
      "Epoch 9: Loss=-0.1771, Benign Acc=0.8998\n",
      "Epoch 10: Loss=-1.2573, Benign Acc=0.8638\n",
      "Epoch 11: Loss=-2.8733, Benign Acc=0.8260\n",
      "Epoch 12: Loss=-3.3186, Benign Acc=0.8193\n",
      "Epoch 13: Loss=-3.4831, Benign Acc=0.8187\n",
      "Epoch 14: Loss=-3.5340, Benign Acc=0.8176\n",
      "Epoch 15: Loss=-3.6121, Benign Acc=0.8176\n",
      "Epoch 16: Loss=-3.6252, Benign Acc=0.8179\n",
      "Epoch 17: Loss=-3.6563, Benign Acc=0.8179\n",
      "Epoch 18: Loss=-3.6808, Benign Acc=0.8177\n",
      "Epoch 19: Loss=-3.6935, Benign Acc=0.8176\n",
      "Epoch 20: Loss=-3.6803, Benign Acc=0.8176\n",
      "✅ Mask training complete.\n",
      "mask raw trained =  tensor([[0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.7000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.9000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.9000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.9000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 0.1000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 0.1000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.9000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.1000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.9000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.9000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.9000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 0.5000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 0.1000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.8000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 1.0000, 0.1000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.8000, 0.9000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.9000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.8000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.1000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.2000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.9000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.4000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.9000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
      "       device='cuda:0')\n",
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_1100.pth_24275dd5-ed29-4154-995d-73c52b2f8081_trigger_visualisation.png\n",
      "epoch: 0, projection version. loss: 0.5945640809928314\n",
      "epoch: 1, projection version. loss: 0.42232067826427994\n",
      "epoch: 2, projection version. loss: 0.34816704558420786\n",
      "epoch: 3, projection version. loss: 0.32862715196760395\n",
      "epoch: 4, projection version. loss: 0.3183675698841674\n",
      "epoch: 5, projection version. loss: 0.3077215088319175\n",
      "epoch: 6, projection version. loss: 0.2944659105961836\n",
      "epoch: 7, projection version. loss: 0.2826386231787597\n",
      "epoch: 8, projection version. loss: 0.26460881851896456\n",
      "epoch: 9, projection version. loss: 0.24855414806287499\n",
      "epoch: 10, projection version. loss: 0.22934556667563283\n",
      "epoch: 11, projection version. loss: 0.20534258222655405\n",
      "epoch: 12, projection version. loss: 0.16095342204163346\n",
      "epoch: 13, projection version. loss: 0.10196510824976088\n",
      "epoch: 14, projection version. loss: 0.022210372163902356\n",
      "epoch: 15, projection version. loss: -0.05425885920943339\n",
      "epoch: 16, projection version. loss: -0.11106605500077145\n",
      "epoch: 17, projection version. loss: -0.1674423780693095\n",
      "epoch: 18, projection version. loss: -0.19916600543015364\n",
      "epoch: 19, projection version. loss: -0.23797108232975006\n",
      "epoch: 20, projection version. loss: -0.2779140400735638\n",
      "epoch: 21, projection version. loss: -0.3160359454871733\n",
      "epoch: 22, projection version. loss: -0.3427717191509054\n",
      "epoch: 23, projection version. loss: -0.3742286493129368\n",
      "epoch: 24, projection version. loss: -0.40967350236222716\n",
      "epoch: 25, projection version. loss: -0.4358785788092432\n",
      "epoch: 26, projection version. loss: -0.4563476545146749\n",
      "epoch: 27, projection version. loss: -0.4818504165999497\n",
      "epoch: 28, projection version. loss: -0.5143570809424678\n",
      "epoch: 29, projection version. loss: -0.5460527139373973\n",
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_1100.pth_dfbecf63-2d50-4ea8-8945-1edd5762941e_trigger_visualisation.png\n",
      "epoch: 0, hinge version. loss: 125771.09132713608\n",
      "epoch: 1, hinge version. loss: 52392.454064477846\n",
      "epoch: 2, hinge version. loss: 29619.65842563291\n",
      "epoch: 3, hinge version. loss: 21179.436993176423\n",
      "epoch: 4, hinge version. loss: 16831.631520717958\n",
      "epoch: 5, hinge version. loss: 11546.628594120846\n",
      "epoch: 6, hinge version. loss: 10420.94807685176\n",
      "epoch: 7, hinge version. loss: 8546.633557283425\n",
      "epoch: 8, hinge version. loss: 6835.834840412382\n",
      "epoch: 9, hinge version. loss: 5108.361720604233\n",
      "epoch: 10, hinge version. loss: 5051.372104306764\n",
      "epoch: 11, hinge version. loss: 6494.1484096865115\n",
      "epoch: 12, hinge version. loss: 4491.397294056566\n",
      "epoch: 13, hinge version. loss: 3215.2151187945014\n",
      "epoch: 14, hinge version. loss: 2499.968569212322\n",
      "epoch: 15, hinge version. loss: 2129.228708774229\n",
      "epoch: 16, hinge version. loss: 2205.845034056072\n",
      "epoch: 17, hinge version. loss: 1372.7495715950108\n",
      "epoch: 18, hinge version. loss: 1736.3182720715486\n",
      "epoch: 19, hinge version. loss: 1069.991477097137\n",
      "epoch: 20, hinge version. loss: 953.0166119925583\n",
      "epoch: 21, hinge version. loss: 15781.946437014809\n",
      "epoch: 22, hinge version. loss: 8144.826105431665\n",
      "epoch: 23, hinge version. loss: 2926.4792140526106\n",
      "epoch: 24, hinge version. loss: 1893.5931373306469\n",
      "epoch: 25, hinge version. loss: 1715.4680554353738\n",
      "epoch: 26, hinge version. loss: 1277.0118466147894\n",
      "epoch: 27, hinge version. loss: 928.4714985135236\n",
      "epoch: 28, hinge version. loss: 834.9377170997329\n",
      "epoch: 29, hinge version. loss: 665.8038617870476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Models:  40%|███████████▏                | 2/5 [13:19<19:57, 399.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_1100.pth_73d754e3-501b-4434-b116-6134b7c6ba3c_trigger_visualisation.png\n",
      "model path  ./Odysseus-CIFAR10/Models/Model_515.pth\n",
      "keys are : dict_keys(['net', 'Model Category', 'Architecture_Name', 'Learning_Rate', 'Loss Function', 'optimizer', 'Momentum', 'Weight decay', 'num_workers', 'Pytorch version', 'Trigger type', 'Trigger Size', 'Trigger_location', 'Mapping', 'Normalization Type', 'Mapping Type', 'Dataset', 'Batch Size', 'trigger_fraction', 'test_clean_acc', 'test_trigerred_acc', 'epoch'])\n",
      "==> Building model..\n",
      "The Accuracies on clean samples:   89.96138996138995\n",
      "The fooling rate:  100.0\n",
      "Mapping is :  0\n",
      "mask raw init =  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Epoch 1: Loss=1.9958, Benign Acc=0.1000\n",
      "Epoch 2: Loss=1.9892, Benign Acc=0.1000\n",
      "Epoch 3: Loss=1.9888, Benign Acc=0.1000\n",
      "Epoch 4: Loss=1.9464, Benign Acc=0.1681\n",
      "Epoch 5: Loss=1.5269, Benign Acc=0.8332\n",
      "Epoch 6: Loss=0.3323, Benign Acc=0.8956\n",
      "Epoch 7: Loss=-0.3438, Benign Acc=0.8961\n",
      "Epoch 8: Loss=-1.1406, Benign Acc=0.8903\n",
      "Epoch 9: Loss=-1.6280, Benign Acc=0.8757\n",
      "Epoch 10: Loss=-1.8430, Benign Acc=0.8603\n",
      "Epoch 11: Loss=-1.9566, Benign Acc=0.8499\n",
      "Epoch 12: Loss=-2.0170, Benign Acc=0.8421\n",
      "Epoch 13: Loss=-2.0532, Benign Acc=0.8358\n",
      "Epoch 14: Loss=-2.0805, Benign Acc=0.8312\n",
      "Epoch 15: Loss=-2.1069, Benign Acc=0.8278\n",
      "Epoch 16: Loss=-2.1317, Benign Acc=0.8252\n",
      "Epoch 17: Loss=-2.1380, Benign Acc=0.8237\n",
      "Epoch 18: Loss=-2.1492, Benign Acc=0.8225\n",
      "Epoch 19: Loss=-2.1571, Benign Acc=0.8218\n",
      "Epoch 20: Loss=-2.1801, Benign Acc=0.8217\n",
      "✅ Mask training complete.\n",
      "mask raw trained =  tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.1000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 0.1000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.9000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.1000, 1.0000,\n",
      "         1.0000, 1.0000, 0.8000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.1000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.9000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.1000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.4000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.8000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.5000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.7000, 0.0000, 1.0000, 0.2000,\n",
      "         0.9000, 1.0000, 1.0000, 1.0000, 0.9000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.3000, 1.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.8000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 0.1000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000, 0.6000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.9000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.1000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.1000]],\n",
      "       device='cuda:0')\n",
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_515.pth_8c23db5b-dd1e-4fe0-8847-1df5453c2eae_trigger_visualisation.png\n",
      "epoch: 0, projection version. loss: 0.2170693551815009\n",
      "epoch: 1, projection version. loss: 0.13058342812936516\n",
      "epoch: 2, projection version. loss: 0.11419666869730889\n",
      "epoch: 3, projection version. loss: 0.10295480169072936\n",
      "epoch: 4, projection version. loss: 0.09629608238045173\n",
      "epoch: 5, projection version. loss: 0.09235232125354718\n",
      "epoch: 6, projection version. loss: 0.08896412936192524\n",
      "epoch: 7, projection version. loss: 0.08704892659111868\n",
      "epoch: 8, projection version. loss: 0.08487008559175685\n",
      "epoch: 9, projection version. loss: 0.08334434173906906\n",
      "epoch: 10, projection version. loss: 0.08219136259978331\n",
      "epoch: 11, projection version. loss: 0.08107606698817844\n",
      "epoch: 12, projection version. loss: 0.08009725582750538\n",
      "epoch: 13, projection version. loss: 0.0788489050125774\n",
      "epoch: 14, projection version. loss: 0.07791145504275455\n",
      "epoch: 15, projection version. loss: 0.07757268581963793\n",
      "epoch: 16, projection version. loss: 0.07597487825381605\n",
      "epoch: 17, projection version. loss: 0.07546115723214572\n",
      "epoch: 18, projection version. loss: 0.07548307957528513\n",
      "epoch: 19, projection version. loss: 0.07637986965194533\n",
      "epoch: 20, projection version. loss: 0.07402556370708006\n",
      "epoch: 21, projection version. loss: 0.0735679492354393\n",
      "epoch: 22, projection version. loss: 0.07205677164506309\n",
      "epoch: 23, projection version. loss: 0.07184698578866222\n",
      "epoch: 24, projection version. loss: 0.07093405053962636\n",
      "epoch: 25, projection version. loss: 0.07067445920238012\n",
      "epoch: 26, projection version. loss: 0.06999958594199977\n",
      "epoch: 27, projection version. loss: 0.0695821299583097\n",
      "epoch: 28, projection version. loss: 0.0689408502812627\n",
      "epoch: 29, projection version. loss: 0.06803429621873022\n",
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_515.pth_220a8c75-f2b0-4577-b297-9cd101139786_trigger_visualisation.png\n",
      "epoch: 0, hinge version. loss: 135089.6991198576\n",
      "epoch: 1, hinge version. loss: 59810.08124011076\n",
      "epoch: 2, hinge version. loss: 33145.67311115506\n",
      "epoch: 3, hinge version. loss: 23401.031559038765\n",
      "epoch: 4, hinge version. loss: 17470.046355814873\n",
      "epoch: 5, hinge version. loss: 10973.19316159019\n",
      "epoch: 6, hinge version. loss: 12427.857387880736\n",
      "epoch: 7, hinge version. loss: 7467.232839077334\n",
      "epoch: 8, hinge version. loss: 6079.72100598299\n",
      "epoch: 9, hinge version. loss: 4998.4184786639635\n",
      "epoch: 10, hinge version. loss: 4009.906087754648\n",
      "epoch: 11, hinge version. loss: 2974.5710480122625\n",
      "epoch: 12, hinge version. loss: 25793.022504202927\n",
      "epoch: 13, hinge version. loss: 5232.413115296183\n",
      "epoch: 14, hinge version. loss: 3655.6687320757514\n",
      "epoch: 15, hinge version. loss: 4964.025004326542\n",
      "epoch: 16, hinge version. loss: 2493.8669427799273\n",
      "epoch: 17, hinge version. loss: 2140.5459834231606\n",
      "epoch: 18, hinge version. loss: 3417.1781654840784\n",
      "epoch: 19, hinge version. loss: 1919.76304838929\n",
      "epoch: 20, hinge version. loss: 1436.5770151645322\n",
      "epoch: 21, hinge version. loss: 1303.9677348076543\n",
      "epoch: 22, hinge version. loss: 1146.4102906818632\n",
      "epoch: 23, hinge version. loss: 2389.6604753325255\n",
      "epoch: 24, hinge version. loss: 1026.9762936362738\n",
      "epoch: 25, hinge version. loss: 951.2390569373022\n",
      "epoch: 26, hinge version. loss: 900.5032085949862\n",
      "epoch: 27, hinge version. loss: 3499.2289351451245\n",
      "epoch: 28, hinge version. loss: 1339.0830831406993\n",
      "epoch: 29, hinge version. loss: 1314.5729791182505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Models:  60%|████████████████▊           | 3/5 [20:00<13:20, 400.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_515.pth_94e489b7-2ca4-4178-b293-2d8d7215b660_trigger_visualisation.png\n",
      "model path  ./Odysseus-CIFAR10/Models/Model_1097.pth\n",
      "keys are : dict_keys(['net', 'Model Category', 'Architecture_Name', 'Learning_Rate', 'Loss Function', 'optimizer', 'Momentum', 'Weight decay', 'num_workers', 'Pytorch version', 'Clean_test_Loss', 'Train_loss', 'Trigerred_test_loss', 'Trigger type', 'Trigger Size', 'Trigger_location', 'Mapping', 'Normalization Type', 'Mapping Type', 'Dataset', 'Batch Size', 'trigger_fraction', 'test_clean_acc', 'test_trigerred_acc', 'epoch'])\n",
      "==> Building model..\n",
      "The Accuracies on clean samples:   90.625\n",
      "The fooling rate:  100.0\n",
      "Mapping is :  8\n",
      "mask raw init =  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Epoch 1: Loss=1.9280, Benign Acc=0.1000\n",
      "Epoch 2: Loss=1.9289, Benign Acc=0.1036\n",
      "Epoch 3: Loss=1.9228, Benign Acc=0.2228\n",
      "Epoch 4: Loss=1.8319, Benign Acc=0.7503\n",
      "Epoch 5: Loss=1.2158, Benign Acc=0.9015\n",
      "Epoch 6: Loss=0.1596, Benign Acc=0.9064\n",
      "Epoch 7: Loss=-0.0223, Benign Acc=0.9042\n",
      "Epoch 8: Loss=-0.1172, Benign Acc=0.8974\n",
      "Epoch 9: Loss=-0.5184, Benign Acc=0.8762\n",
      "Epoch 10: Loss=-1.8447, Benign Acc=0.8364\n",
      "Epoch 11: Loss=-2.6185, Benign Acc=0.8217\n",
      "Epoch 12: Loss=-2.8403, Benign Acc=0.8178\n",
      "Epoch 13: Loss=-2.9124, Benign Acc=0.8165\n",
      "Epoch 14: Loss=-2.9710, Benign Acc=0.8160\n",
      "Epoch 15: Loss=-3.0282, Benign Acc=0.8153\n",
      "Epoch 16: Loss=-3.0481, Benign Acc=0.8149\n",
      "Epoch 17: Loss=-3.0746, Benign Acc=0.8147\n",
      "Epoch 18: Loss=-3.0813, Benign Acc=0.8143\n",
      "Epoch 19: Loss=-3.0802, Benign Acc=0.8144\n",
      "Epoch 20: Loss=-3.0890, Benign Acc=0.8147\n",
      "✅ Mask training complete.\n",
      "mask raw trained =  tensor([[0.0000, 1.0000, 1.0000, 1.0000, 0.1000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.9000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.7000, 1.0000, 1.0000, 0.8000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.1000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.9000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.9000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.1000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 0.0000, 1.0000, 0.2000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.1000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.2000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.1000,\n",
      "         0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.3000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.9000, 1.0000, 0.0000, 1.0000, 1.0000, 0.7000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.8000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 0.9000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.3000,\n",
      "         0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.8000,\n",
      "         0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000]],\n",
      "       device='cuda:0')\n",
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_1097.pth_f4ecd5c6-96e2-4eec-90d6-7c69eca862e2_trigger_visualisation.png\n",
      "epoch: 0, projection version. loss: 0.380034093615375\n",
      "epoch: 1, projection version. loss: -1.6793501066350485\n",
      "epoch: 2, projection version. loss: -8.291330862648879\n",
      "epoch: 3, projection version. loss: -11.31049049956889\n",
      "epoch: 4, projection version. loss: -12.468767021275774\n",
      "epoch: 5, projection version. loss: -13.096696274190009\n",
      "epoch: 6, projection version. loss: -13.505164086064205\n",
      "epoch: 7, projection version. loss: -13.814873876450937\n",
      "epoch: 8, projection version. loss: -14.088845965228503\n",
      "epoch: 9, projection version. loss: -14.318986663335487\n",
      "epoch: 10, projection version. loss: -14.520664915253844\n",
      "epoch: 11, projection version. loss: -14.667710593984097\n",
      "epoch: 12, projection version. loss: -14.811615026449855\n",
      "epoch: 13, projection version. loss: -14.916649383834645\n",
      "epoch: 14, projection version. loss: -15.058249775367447\n",
      "epoch: 15, projection version. loss: -15.148082853872564\n",
      "epoch: 16, projection version. loss: -15.229999445661713\n",
      "epoch: 17, projection version. loss: -15.267527387112002\n",
      "epoch: 18, projection version. loss: -15.375855457933643\n",
      "epoch: 19, projection version. loss: -15.446863343444052\n",
      "epoch: 20, projection version. loss: -15.518863593475729\n",
      "epoch: 21, projection version. loss: -15.572533583339256\n",
      "epoch: 22, projection version. loss: -15.63701546343067\n",
      "epoch: 23, projection version. loss: -15.72130881683736\n",
      "epoch: 24, projection version. loss: -15.758803536620322\n",
      "epoch: 25, projection version. loss: -15.818445253975783\n",
      "epoch: 26, projection version. loss: -15.874656061582927\n",
      "epoch: 27, projection version. loss: -15.942740440368652\n",
      "epoch: 28, projection version. loss: -16.047051960908913\n",
      "epoch: 29, projection version. loss: -16.007708646074125\n",
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_1097.pth_057054bd-dc4d-4306-87e7-67732f5e9191_trigger_visualisation.png\n",
      "epoch: 0, hinge version. loss: 133267.93453322785\n",
      "epoch: 1, hinge version. loss: 61738.12640921677\n",
      "epoch: 2, hinge version. loss: 33956.43349485759\n",
      "epoch: 3, hinge version. loss: 21536.220523882515\n",
      "epoch: 4, hinge version. loss: 15625.648524030854\n",
      "epoch: 5, hinge version. loss: 12600.692939082279\n",
      "epoch: 6, hinge version. loss: 14353.226176201542\n",
      "epoch: 7, hinge version. loss: 7140.567274648932\n",
      "epoch: 8, hinge version. loss: 7093.2541473002375\n",
      "epoch: 9, hinge version. loss: 5011.854825949367\n",
      "epoch: 10, hinge version. loss: 4816.7548920836625\n",
      "epoch: 11, hinge version. loss: 10548.753133653085\n",
      "epoch: 12, hinge version. loss: 4254.528219874901\n",
      "epoch: 13, hinge version. loss: 2901.3385983237736\n",
      "epoch: 14, hinge version. loss: 3480.5703526750394\n",
      "epoch: 15, hinge version. loss: 1972.7306904853144\n",
      "epoch: 16, hinge version. loss: 1571.6266023660007\n",
      "epoch: 17, hinge version. loss: 1438.9583353935918\n",
      "epoch: 18, hinge version. loss: 1492.5294842297517\n",
      "epoch: 19, hinge version. loss: 998.0208241909365\n",
      "epoch: 20, hinge version. loss: 2415.4842243436015\n",
      "epoch: 21, hinge version. loss: 1173.9794052703471\n",
      "epoch: 22, hinge version. loss: 951.7393371968329\n",
      "epoch: 23, hinge version. loss: 1258.8070842887782\n",
      "epoch: 24, hinge version. loss: 836.8445370831067\n",
      "epoch: 25, hinge version. loss: 605.691641119462\n",
      "epoch: 26, hinge version. loss: 449.79085695290865\n",
      "epoch: 27, hinge version. loss: 354.9617568390279\n",
      "epoch: 28, hinge version. loss: 258.7693148625048\n",
      "epoch: 29, hinge version. loss: 249.45053849039198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Models:  80%|██████████████████████▍     | 4/5 [26:31<06:36, 396.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_1097.pth_f01fda34-688d-4533-8303-507ee4472d56_trigger_visualisation.png\n",
      "model path  ./Odysseus-CIFAR10/Models/Model_518.pth\n",
      "keys are : dict_keys(['net', 'Model Category', 'Architecture_Name', 'Learning_Rate', 'Loss Function', 'optimizer', 'Momentum', 'Weight decay', 'num_workers', 'Pytorch version', 'Trigger type', 'Trigger Size', 'Trigger_location', 'Mapping', 'Normalization Type', 'Mapping Type', 'Dataset', 'Batch Size', 'trigger_fraction', 'test_clean_acc', 'test_trigerred_acc', 'epoch'])\n",
      "==> Building model..\n",
      "The Accuracies on clean samples:   89.42883770469977\n",
      "The fooling rate:  100.0\n",
      "Mapping is :  4\n",
      "mask raw init =  tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "Epoch 1: Loss=1.9903, Benign Acc=0.1000\n",
      "Epoch 2: Loss=1.9894, Benign Acc=0.1000\n",
      "Epoch 3: Loss=1.9858, Benign Acc=0.1011\n",
      "Epoch 4: Loss=1.9388, Benign Acc=0.3568\n",
      "Epoch 5: Loss=1.5177, Benign Acc=0.8685\n",
      "Epoch 6: Loss=0.3491, Benign Acc=0.8949\n",
      "Epoch 7: Loss=-0.2148, Benign Acc=0.8945\n",
      "Epoch 8: Loss=-1.0190, Benign Acc=0.8855\n",
      "Epoch 9: Loss=-1.6148, Benign Acc=0.8719\n",
      "Epoch 10: Loss=-1.8376, Benign Acc=0.8568\n",
      "Epoch 11: Loss=-1.9463, Benign Acc=0.8457\n",
      "Epoch 12: Loss=-2.0058, Benign Acc=0.8382\n",
      "Epoch 13: Loss=-2.0368, Benign Acc=0.8335\n",
      "Epoch 14: Loss=-2.0658, Benign Acc=0.8307\n",
      "Epoch 15: Loss=-2.0862, Benign Acc=0.8281\n",
      "Epoch 16: Loss=-2.1035, Benign Acc=0.8250\n",
      "Epoch 17: Loss=-2.1197, Benign Acc=0.8239\n",
      "Epoch 18: Loss=-2.1269, Benign Acc=0.8225\n",
      "Epoch 19: Loss=-2.1293, Benign Acc=0.8213\n",
      "Epoch 20: Loss=-2.1308, Benign Acc=0.8201\n",
      "✅ Mask training complete.\n",
      "mask raw trained =  tensor([[1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.4000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.4000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.7000, 1.0000, 1.0000, 0.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.4000, 0.0000,\n",
      "         1.0000, 1.0000, 0.2000, 1.0000, 1.0000, 0.0000, 1.0000, 0.1000, 1.0000,\n",
      "         1.0000, 0.1000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000, 1.0000, 0.9000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 0.0000, 0.9000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 0.2000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.1000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.6000, 1.0000, 1.0000, 0.1000, 1.0000, 1.0000, 0.9000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         0.1000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.2000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.1000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000, 0.3000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.1000,\n",
      "         1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         0.0000, 0.3000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.7000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000, 0.1000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.9000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.1000, 1.0000, 1.0000, 0.0000, 1.0000]],\n",
      "       device='cuda:0')\n",
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_518.pth_89069690-e09b-4db0-9fff-14512dd47c98_trigger_visualisation.png\n",
      "epoch: 0, projection version. loss: 0.20337491473065147\n",
      "epoch: 1, projection version. loss: 0.15010646438296837\n",
      "epoch: 2, projection version. loss: 0.13340377015403554\n",
      "epoch: 3, projection version. loss: 0.1271751092959054\n",
      "epoch: 4, projection version. loss: 0.12218731349404854\n",
      "epoch: 5, projection version. loss: 0.11613531071173994\n",
      "epoch: 6, projection version. loss: 0.11218553508007073\n",
      "epoch: 7, projection version. loss: 0.10954837246408945\n",
      "epoch: 8, projection version. loss: 0.10628484048043625\n",
      "epoch: 9, projection version. loss: 0.10346332013229781\n",
      "epoch: 10, projection version. loss: 0.10187909422041494\n",
      "epoch: 11, projection version. loss: 0.10010449578867683\n",
      "epoch: 12, projection version. loss: 0.09904080874557737\n",
      "epoch: 13, projection version. loss: 0.09795934820099722\n",
      "epoch: 14, projection version. loss: 0.09683154957203925\n",
      "epoch: 15, projection version. loss: 0.09454443635819834\n",
      "epoch: 16, projection version. loss: 0.09326248964931391\n",
      "epoch: 17, projection version. loss: 0.09298814201279532\n",
      "epoch: 18, projection version. loss: 0.09103913548626477\n",
      "epoch: 19, projection version. loss: 0.09020535874215863\n",
      "epoch: 20, projection version. loss: 0.08879566183195839\n",
      "epoch: 21, projection version. loss: 0.0881730832065208\n",
      "epoch: 22, projection version. loss: 0.0868368646766566\n",
      "epoch: 23, projection version. loss: 0.08643405148877373\n",
      "epoch: 24, projection version. loss: 0.0850367733760725\n",
      "epoch: 25, projection version. loss: 0.08361627397280705\n",
      "epoch: 26, projection version. loss: 0.08243779272218293\n",
      "epoch: 27, projection version. loss: 0.08156874596695357\n",
      "epoch: 28, projection version. loss: 0.07972458316178262\n",
      "epoch: 29, projection version. loss: 0.07866611633496949\n",
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_518.pth_f9f292a2-e41e-48a9-a4f8-ca7ab33e609c_trigger_visualisation.png\n",
      "epoch: 0, hinge version. loss: 132857.68774723102\n",
      "epoch: 1, hinge version. loss: 60831.8046133307\n",
      "epoch: 2, hinge version. loss: 33768.02426572389\n",
      "epoch: 3, hinge version. loss: 19501.36350375791\n",
      "epoch: 4, hinge version. loss: 15763.563365308544\n",
      "epoch: 5, hinge version. loss: 10580.901898734177\n",
      "epoch: 6, hinge version. loss: 8454.783147498023\n",
      "epoch: 7, hinge version. loss: 7205.1351132936115\n",
      "epoch: 8, hinge version. loss: 5305.391406868078\n",
      "epoch: 9, hinge version. loss: 4292.2320742063885\n",
      "epoch: 10, hinge version. loss: 3697.4469643122034\n",
      "epoch: 11, hinge version. loss: 3288.963115450702\n",
      "epoch: 12, hinge version. loss: 3897.0351717019385\n",
      "epoch: 13, hinge version. loss: 6172.227616322191\n",
      "epoch: 14, hinge version. loss: 3449.079010396064\n",
      "epoch: 15, hinge version. loss: 1843.6514100666288\n",
      "epoch: 16, hinge version. loss: 1532.2334023004846\n",
      "epoch: 17, hinge version. loss: 4328.582908147498\n",
      "epoch: 18, hinge version. loss: 1498.9400202111353\n",
      "epoch: 19, hinge version. loss: 1941.1556041089793\n",
      "epoch: 20, hinge version. loss: 1145.624792944027\n",
      "epoch: 21, hinge version. loss: 1051.779395574256\n",
      "epoch: 22, hinge version. loss: 1104.151756769494\n",
      "epoch: 23, hinge version. loss: 866.1996009923234\n",
      "epoch: 24, hinge version. loss: 856.1951635819447\n",
      "epoch: 25, hinge version. loss: 2114.4711268944075\n",
      "epoch: 26, hinge version. loss: 818.4109753958786\n",
      "epoch: 27, hinge version. loss: 633.732584120352\n",
      "epoch: 28, hinge version. loss: 39336.21663907208\n",
      "epoch: 29, hinge version. loss: 20891.184496143196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Models: 100%|████████████████████████████| 5/5 [32:58<00:00, 395.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved CIFAR trigger visualisation to trigger_visualisations/Model_518.pth_ca1adbe6-3f5f-483e-93c8-93b163de5405_trigger_visualisation.png\n",
      "✅ Results saved to CIFAR10_experiment_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model list\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Prepare data if not already present\n",
    "print(\"Preparing CIFAR10 dataset...\")\n",
    "prepare_cifar10_data()\n",
    "\n",
    "# Get transforms\n",
    "transform_test = transforms.ToTensor()\n",
    "\n",
    "unet_loss=loss_bti_dbf_paper\n",
    "\n",
    "unet_factory = partial(UNet, n_channels=3, num_classes=3, base_filter_num=32, num_blocks=4)\n",
    "\n",
    "# Create test dataset\n",
    "test_dataset = SimpleCIFAR10Dataset(\n",
    "    path_to_data='./CIFAR10_Data/clean',\n",
    "    csv_filename='clean.csv',\n",
    "    data_transform=transform_test\n",
    ")\n",
    "\n",
    "variants = [\n",
    "    {\n",
    "        \"name\": \"paper-branch\",\n",
    "        \"train_fn\": \"branch\",          # uses UNet.train_generator\n",
    "        \"unet_loss\": loss_bti_dbf_paper,\n",
    "        \"tau\": 3,\n",
    "        \"epochs\": 30,\n",
    "        \"lr\": 0.01,\n",
    "        \"p\": 2,\n",
    "        \"visualize\": True,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"projection\",\n",
    "        \"train_fn\": \"projection\",      # uses UNet.train_generator_projection\n",
    "        \"unet_loss\": loss_bti_dbf_paper,\n",
    "        \"tau\": 3,\n",
    "        \"epochs\": 30,\n",
    "        \"lr\": 0.01,\n",
    "        \"p\": 2,\n",
    "        \"visualize\": True,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"hinge\",\n",
    "        \"train_fn\": \"hinge\",           # uses UNet.train_generator_hinge\n",
    "        \"unet_loss\": loss_bti_dbf_paper,\n",
    "        \"tau\": 3,\n",
    "        \"epochs\": 30,\n",
    "        \"lr\": 0.01,\n",
    "        \"p\": 2,\n",
    "        \"lambda_tau\": 5000,\n",
    "        \"visualize\": True,\n",
    "    },\n",
    "]\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "test_BTI_DBF_param(\n",
    "    device=device,\n",
    "    num_models=5,\n",
    "    model_list='./test_results/CIFAR10_Models_20250808_182429.csv',\n",
    "    model_dir='./Odysseus-CIFAR10/Models',\n",
    "    model_type='CIFAR10',\n",
    "    unet_factory=unet_factory,\n",
    "    dataloader=dataloader,\n",
    "    variants=variants,\n",
    "    mask_epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d944f5b-d9fc-40f1-b426-ea63fb76d56a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ResearchProject)",
   "language": "python",
   "name": "researchproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
